{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAE-Optimized Training with Isotonic Calibration\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
        "from rdkit.Chem import AllChem, DataStructs\n",
        "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"‚úÖ MAE-optimized training with isotonic calibration loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimized Featurization Functions\n",
        "def smiles_to_mol(s):\n",
        "    try:\n",
        "        return Chem.MolFromSmiles(s)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Optimized descriptor functions\n",
        "RD_DESC_FUNCS = [\n",
        "    Descriptors.MolWt, Descriptors.MolLogP, Descriptors.TPSA,\n",
        "    Descriptors.HeavyAtomCount, Descriptors.NumHAcceptors,\n",
        "    Descriptors.NumHDonors, Descriptors.NumValenceElectrons,\n",
        "    Descriptors.FractionCSP3, Descriptors.RingCount,\n",
        "    Descriptors.BertzCT, Descriptors.BalabanJ,\n",
        "]\n",
        "\n",
        "def morgan_bits_optimized(mol, n_bits=1024, radius=2):\n",
        "    \"\"\"Optimized Morgan fingerprint generation using modern API\"\"\"\n",
        "    try:\n",
        "        generator = GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
        "        fp = generator.GetFingerprint(mol)\n",
        "        arr = np.zeros((n_bits,), dtype=np.uint8)\n",
        "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "        return arr\n",
        "    except:\n",
        "        return np.zeros(n_bits, dtype=np.uint8)\n",
        "\n",
        "def smiles_stats_optimized(smiles):\n",
        "    \"\"\"Optimized SMILES statistics calculation\"\"\"\n",
        "    s = smiles\n",
        "    counts = {\n",
        "        'len': len(s),\n",
        "        'paren_open': s.count('('),\n",
        "        'paren_close': s.count(')'),\n",
        "        'aromatic_c': s.count('c'),\n",
        "        'aliphatic_C': s.count('C'),\n",
        "        'num_brackets': s.count('['),\n",
        "        'num_equals': s.count('='),\n",
        "        'num_hash': s.count('#'),\n",
        "    }\n",
        "    for tok in ['O','N','F','Cl','Br','S','P']:\n",
        "        counts[f'atom_{tok}'] = s.count(tok)\n",
        "    for d in '123456':\n",
        "        counts[f'ring_{d}']= s.count(d)\n",
        "    counts['aromatic_ratio'] = counts['aromatic_c'] / max(1, counts['aliphatic_C']+counts['aromatic_c'])\n",
        "    return counts\n",
        "\n",
        "def featurize_optimized(df, smiles_col='SMILES', n_bits=1024):\n",
        "    \"\"\"Optimized featurization with reduced feature count and modern RDKit API\"\"\"\n",
        "    rows = []\n",
        "    desc_cols = [f.__name__ for f in RD_DESC_FUNCS]\n",
        "    maccs_cols = [f\"MACCS_{i}\" for i in range(167)]\n",
        "    ecfp_cols = [f\"ECFP_{i}\" for i in range(n_bits)]\n",
        "    stat_cols = None\n",
        "\n",
        "    maccs_generator = GetMorganGenerator(radius=1, fpSize=167)\n",
        "    \n",
        "    for i, s in enumerate(df[smiles_col].values):\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"  Processing {i}/{len(df)} molecules...\")\n",
        "            \n",
        "        mol = smiles_to_mol(s)\n",
        "        if mol is None:\n",
        "            rows.append([np.nan] * (len(desc_cols) + 167 + n_bits + 15))\n",
        "            continue\n",
        "            \n",
        "        try:\n",
        "            # RDKit descriptors\n",
        "            desc = [f(mol) for f in RD_DESC_FUNCS]\n",
        "            \n",
        "            # MACCS-like features using Morgan\n",
        "            maccs_fp = maccs_generator.GetFingerprint(mol)\n",
        "            maccs_arr = np.zeros((167,), dtype=np.uint8)\n",
        "            DataStructs.ConvertToNumpyArray(maccs_fp, maccs_arr)\n",
        "            \n",
        "            # ECFP\n",
        "            ecfp = morgan_bits_optimized(mol, n_bits=n_bits, radius=2)\n",
        "            \n",
        "            # SMILES stats\n",
        "            st = smiles_stats_optimized(s)\n",
        "            if stat_cols is None:\n",
        "                stat_cols = list(st.keys())\n",
        "            \n",
        "            rows.append(np.concatenate([desc, maccs_arr, ecfp, np.array([st[k] for k in stat_cols])], axis=0))\n",
        "            \n",
        "        except Exception as e:\n",
        "            rows.append([np.nan] * (len(desc_cols) + 167 + n_bits + 15))\n",
        "    \n",
        "    X = np.vstack(rows)\n",
        "    columns = desc_cols + maccs_cols + ecfp_cols + stat_cols\n",
        "    return pd.DataFrame(X, columns=columns)\n",
        "\n",
        "print(\"‚úÖ Optimized featurization functions loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Isotonic Calibration Functions\n",
        "class IsotonicCalibrator:\n",
        "    \"\"\"\n",
        "    Isotonic regression calibrator for regression tasks\n",
        "    Corrects systematic biases in model predictions\n",
        "    \"\"\"\n",
        "    def __init__(self, target_name):\n",
        "        self.target_name = target_name\n",
        "        self.calibrator = IsotonicRegression(out_of_bounds='clip')\n",
        "        self.is_fitted = False\n",
        "        \n",
        "    def fit(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Fit isotonic regression to calibrate predictions\n",
        "        \n",
        "        Args:\n",
        "            y_true: True target values\n",
        "            y_pred: Model predictions\n",
        "        \"\"\"\n",
        "        print(f\"üîß Fitting isotonic calibrator for {self.target_name}...\")\n",
        "        \n",
        "        # Remove any NaN values\n",
        "        valid_mask = ~(np.isnan(y_true) | np.isnan(y_pred))\n",
        "        y_true_clean = y_true[valid_mask]\n",
        "        y_pred_clean = y_pred[valid_mask]\n",
        "        \n",
        "        if len(y_true_clean) == 0:\n",
        "            print(f\"‚ö†Ô∏è No valid data for {self.target_name} calibration\")\n",
        "            return\n",
        "        \n",
        "        # Fit isotonic regression\n",
        "        self.calibrator.fit(y_pred_clean, y_true_clean)\n",
        "        self.is_fitted = True\n",
        "        \n",
        "        # Calculate calibration improvement\n",
        "        original_mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "        calibrated_pred = self.calibrator.predict(y_pred_clean)\n",
        "        calibrated_mae = mean_absolute_error(y_true_clean, calibrated_pred)\n",
        "        \n",
        "        improvement = original_mae - calibrated_mae\n",
        "        print(f\"   Original MAE: {original_mae:.4f}\")\n",
        "        print(f\"   Calibrated MAE: {calibrated_mae:.4f}\")\n",
        "        print(f\"   Improvement: {improvement:.4f} ({improvement/original_mae*100:.2f}%)\")\n",
        "        \n",
        "    def predict(self, y_pred):\n",
        "        \"\"\"\n",
        "        Apply calibration to predictions\n",
        "        \n",
        "        Args:\n",
        "            y_pred: Model predictions to calibrate\n",
        "            \n",
        "        Returns:\n",
        "            Calibrated predictions\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            print(f\"‚ö†Ô∏è Calibrator for {self.target_name} not fitted, returning original predictions\")\n",
        "            return y_pred\n",
        "        \n",
        "        return self.calibrator.predict(y_pred)\n",
        "    \n",
        "    def get_calibration_info(self):\n",
        "        \"\"\"\n",
        "        Get information about the calibration\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            return f\"{self.target_name}: Not fitted\"\n",
        "        \n",
        "        return f\"{self.target_name}: Fitted with {len(self.calibrator.X_thresholds_)} knots\"\n",
        "\n",
        "def create_calibration_ensemble(predictions_dict, calibrators_dict):\n",
        "    \"\"\"\n",
        "    Create calibrated ensemble predictions\n",
        "    \n",
        "    Args:\n",
        "        predictions_dict: Dict of {target: predictions}\n",
        "        calibrators_dict: Dict of {target: IsotonicCalibrator}\n",
        "        \n",
        "    Returns:\n",
        "        Dict of {target: calibrated_predictions}\n",
        "    \"\"\"\n",
        "    calibrated_predictions = {}\n",
        "    \n",
        "    for target, predictions in predictions_dict.items():\n",
        "        if target in calibrators_dict:\n",
        "            calibrated_pred = calibrators_dict[target].predict(predictions)\n",
        "            calibrated_predictions[target] = calibrated_pred\n",
        "            print(f\"‚úÖ {target}: Applied calibration\")\n",
        "        else:\n",
        "            calibrated_predictions[target] = predictions\n",
        "            print(f\"‚ö†Ô∏è {target}: No calibrator found, using original predictions\")\n",
        "    \n",
        "    return calibrated_predictions\n",
        "\n",
        "print(\"‚úÖ Isotonic calibration functions loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAE-Optimized Training with Calibration\n",
        "def train_mae_calibrated_cv(train_df, test_df, target, n_folds=3, n_clusters=15):\n",
        "    \"\"\"\n",
        "    Training with MAE-optimized objectives + isotonic calibration\n",
        "    \"\"\"\n",
        "    print(f\"\\nüéØ MAE-OPTIMIZED + CALIBRATED Training for {target}...\")\n",
        "    \n",
        "    # Prepare data\n",
        "    train_subset = train_df[train_df[target].notna()].copy()\n",
        "    train_smiles = train_subset['SMILES'].tolist()\n",
        "    test_smiles = test_df['SMILES'].tolist()\n",
        "    \n",
        "    print(f\"Training samples: {len(train_subset)}\")\n",
        "    print(f\"Test samples: {len(test_df)}\")\n",
        "    \n",
        "    # Check target distribution\n",
        "    y = train_subset[target].values\n",
        "    print(f\"Target range: {y.min():.2f} to {y.max():.2f}\")\n",
        "    print(f\"Target mean: {y.mean():.2f}, std: {y.std():.2f}\")\n",
        "    \n",
        "    # Featurize data\n",
        "    print(\"üîß Featurizing data...\")\n",
        "    try:\n",
        "        train_features = featurize_optimized(train_subset, smiles_col='SMILES', n_bits=512)\n",
        "        test_features = featurize_optimized(test_df, smiles_col='SMILES', n_bits=512)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Featurization failed: {e}\")\n",
        "        return None, None, None, float('inf'), 0.5\n",
        "    \n",
        "    # Handle missing values and infinite values\n",
        "    train_features = train_features.fillna(0)\n",
        "    test_features = test_features.fillna(0)\n",
        "    train_features = train_features.replace([np.inf, -np.inf], 0)\n",
        "    test_features = test_features.replace([np.inf, -np.inf], 0)\n",
        "    \n",
        "    print(f\"Feature matrix shape: {train_features.shape}\")\n",
        "    \n",
        "    # Remove constant features\n",
        "    constant_features = train_features.columns[train_features.nunique() <= 1]\n",
        "    if len(constant_features) > 0:\n",
        "        print(f\"Removing {len(constant_features)} constant features\")\n",
        "        train_features = train_features.drop(columns=constant_features)\n",
        "        test_features = test_features.drop(columns=constant_features)\n",
        "    \n",
        "    # Adversarial validation\n",
        "    try:\n",
        "        print(\"üîç Adversarial validation...\")\n",
        "        train_labels = np.zeros(len(train_features))\n",
        "        test_labels = np.ones(len(test_features))\n",
        "        \n",
        "        X_adv = np.vstack([train_features.values, test_features.values])\n",
        "        y_adv = np.hstack([train_labels, test_labels])\n",
        "        \n",
        "        adv_model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)\n",
        "        adv_model.fit(X_adv, y_adv)\n",
        "        \n",
        "        train_probs = adv_model.predict_proba(train_features.values)[:, 1]\n",
        "        adv_auc = roc_auc_score(y_adv, adv_model.predict_proba(X_adv)[:, 1])\n",
        "        \n",
        "        # Create bounded sample weights\n",
        "        sample_weights = 1.0 / (train_probs + 0.1)\n",
        "        sample_weights = np.clip(sample_weights, 0.5, 2.0)\n",
        "        sample_weights = sample_weights / np.mean(sample_weights)\n",
        "        \n",
        "        print(f\"Adversarial AUC: {adv_auc:.4f}\")\n",
        "        print(f\"Sample weights range: {sample_weights.min():.3f} to {sample_weights.max():.3f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Adversarial validation failed: {e}\")\n",
        "        sample_weights = np.ones(len(train_subset))\n",
        "        adv_auc = 0.5\n",
        "    \n",
        "    # Create ECFP clusters for GroupKFold\n",
        "    try:\n",
        "        print(\"üîó Creating ECFP clusters...\")\n",
        "        ecfp_features = []\n",
        "        valid_indices = []\n",
        "        \n",
        "        for i, smiles in enumerate(train_smiles):\n",
        "            if i % 500 == 0:\n",
        "                print(f\"  Processing {i}/{len(train_smiles)} molecules for clustering...\")\n",
        "                \n",
        "            mol = smiles_to_mol(smiles)\n",
        "            if mol is not None:\n",
        "                ecfp = morgan_bits_optimized(mol, n_bits=256, radius=2)\n",
        "                ecfp_features.append(ecfp)\n",
        "                valid_indices.append(i)\n",
        "        \n",
        "        if len(ecfp_features) > 0:\n",
        "            ecfp_features = np.array(ecfp_features)\n",
        "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=5)\n",
        "            cluster_labels = kmeans.fit_predict(ecfp_features)\n",
        "            \n",
        "            clusters = np.zeros(len(train_smiles), dtype=int)\n",
        "            clusters[valid_indices] = cluster_labels\n",
        "            print(f\"Cluster distribution: {np.bincount(clusters)}\")\n",
        "        else:\n",
        "            clusters = np.zeros(len(train_smiles), dtype=int)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Clustering failed: {e}\")\n",
        "        clusters = np.zeros(len(train_smiles), dtype=int)\n",
        "    \n",
        "    # GroupKFold\n",
        "    group_kfold = GroupKFold(n_splits=n_folds)\n",
        "    \n",
        "    # Store predictions\n",
        "    oof_predictions = np.zeros(len(train_subset))\n",
        "    test_predictions = np.zeros(len(test_df))\n",
        "    \n",
        "    # MAE-optimized model parameters\n",
        "    if target == \"Tg\":\n",
        "        xgb_params = {\n",
        "            'objective': 'reg:absoluteerror',\n",
        "            'eval_metric': 'mae',\n",
        "            'n_estimators': 1000,\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 4,\n",
        "            'reg_lambda': 1.0,\n",
        "            'reg_alpha': 0.1,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'random_state': 4,\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "        lgb_params = {\n",
        "            'objective': 'mae',\n",
        "            'metric': 'mae',\n",
        "            'n_estimators': 800,\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 4,\n",
        "            'num_leaves': 31,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'reg_alpha': 0.1,\n",
        "            'reg_lambda': 1.0,\n",
        "            'random_state': 42,\n",
        "            'n_jobs': -1,\n",
        "            'verbosity': -1\n",
        "        }\n",
        "        cat_params = {\n",
        "            'loss_function': 'MAE',\n",
        "            'eval_metric': 'MAE',\n",
        "            'iterations': 800,\n",
        "            'learning_rate': 0.05,\n",
        "            'depth': 4,\n",
        "            'l2_leaf_reg': 1.0,\n",
        "            'random_strength': 0.1,\n",
        "            'random_seed': 42,\n",
        "            'verbose': False,\n",
        "            'task_type': 'CPU'\n",
        "        }\n",
        "    else:\n",
        "        # Conservative parameters for other targets\n",
        "        xgb_params = {\n",
        "            'objective': 'reg:absoluteerror',\n",
        "            'eval_metric': 'mae',\n",
        "            'n_estimators': 600,\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 3,\n",
        "            'reg_lambda': 1.0,\n",
        "            'random_state': 4,\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "        lgb_params = {\n",
        "            'objective': 'mae',\n",
        "            'metric': 'mae',\n",
        "            'n_estimators': 500,\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 3,\n",
        "            'random_state': 42,\n",
        "            'n_jobs': -1,\n",
        "            'verbosity': -1\n",
        "        }\n",
        "        cat_params = {\n",
        "            'loss_function': 'MAE',\n",
        "            'eval_metric': 'MAE',\n",
        "            'iterations': 500,\n",
        "            'learning_rate': 0.05,\n",
        "            'depth': 3,\n",
        "            'random_seed': 42,\n",
        "            'verbose': False,\n",
        "            'task_type': 'CPU'\n",
        "        }\n",
        "    \n",
        "    # Cross-validation with MAE-optimized ensemble\n",
        "    fold_scores = []\n",
        "    \n",
        "    try:\n",
        "        for fold, (train_idx, val_idx) in enumerate(group_kfold.split(train_features, y, groups=clusters)):\n",
        "            print(f\"  Fold {fold + 1}/{n_folds}\")\n",
        "            \n",
        "            # Split data\n",
        "            X_train_fold = train_features.iloc[train_idx]\n",
        "            X_val_fold = train_features.iloc[val_idx]\n",
        "            y_train_fold = y[train_idx]\n",
        "            y_val_fold = y[val_idx]\n",
        "            weights_fold = sample_weights[train_idx]\n",
        "            \n",
        "            # Train XGBoost with MAE objective\n",
        "            xgb_model = XGBRegressor(**xgb_params)\n",
        "            xgb_model.fit(\n",
        "                X_train_fold, y_train_fold,\n",
        "                sample_weight=weights_fold,\n",
        "                eval_set=[(X_val_fold, y_val_fold)],\n",
        "                early_stopping_rounds=30,\n",
        "                verbose=False\n",
        "            )\n",
        "            \n",
        "            # Train LightGBM with MAE objective\n",
        "            lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
        "            lgb_model.fit(\n",
        "                X_train_fold, y_train_fold,\n",
        "                sample_weight=weights_fold,\n",
        "                eval_set=[(X_val_fold, y_val_fold)],\n",
        "                callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
        "            )\n",
        "            \n",
        "            # Train CatBoost with MAE objective\n",
        "            cat_model = CatBoostRegressor(**cat_params)\n",
        "            cat_model.fit(\n",
        "                X_train_fold, y_train_fold,\n",
        "                sample_weight=weights_fold,\n",
        "                eval_set=(X_val_fold, y_val_fold),\n",
        "                early_stopping_rounds=30,\n",
        "                verbose=False\n",
        "            )\n",
        "            \n",
        "            # Ensemble predictions\n",
        "            val_pred_xgb = xgb_model.predict(X_val_fold)\n",
        "            val_pred_lgb = lgb_model.predict(X_val_fold)\n",
        "            val_pred_cat = cat_model.predict(X_val_fold)\n",
        "            val_pred_ensemble = (val_pred_xgb + val_pred_lgb + val_pred_cat) / 3\n",
        "            \n",
        "            test_pred_xgb = xgb_model.predict(test_features)\n",
        "            test_pred_lgb = lgb_model.predict(test_features)\n",
        "            test_pred_cat = cat_model.predict(test_features)\n",
        "            test_pred_ensemble = (test_pred_xgb + test_pred_lgb + test_pred_cat) / 3\n",
        "            \n",
        "            # Store predictions\n",
        "            oof_predictions[val_idx] = val_pred_ensemble\n",
        "            test_predictions += test_pred_ensemble / n_folds\n",
        "            \n",
        "            # Calculate fold score\n",
        "            fold_mae = mean_absolute_error(y_val_fold, val_pred_ensemble)\n",
        "            fold_scores.append(fold_mae)\n",
        "            print(f\"    Fold {fold + 1} MAE: {fold_mae:.4f}\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Cross-validation failed: {e}\")\n",
        "        return None, None, None, float('inf'), adv_auc\n",
        "    \n",
        "    # Overall performance before calibration\n",
        "    overall_mae = mean_absolute_error(y, oof_predictions)\n",
        "    print(f\"  Overall CV MAE (before calibration): {overall_mae:.4f}\")\n",
        "    print(f\"  CV std: {np.std(fold_scores):.4f}\")\n",
        "    \n",
        "    # Create and fit isotonic calibrator\n",
        "    calibrator = IsotonicCalibrator(target)\n",
        "    calibrator.fit(y, oof_predictions)\n",
        "    \n",
        "    # Apply calibration to OOF predictions\n",
        "    calibrated_oof = calibrator.predict(oof_predictions)\n",
        "    calibrated_mae = mean_absolute_error(y, calibrated_oof)\n",
        "    \n",
        "    print(f\"  Overall CV MAE (after calibration): {calibrated_mae:.4f}\")\n",
        "    print(f\"  Calibration improvement: {overall_mae - calibrated_mae:.4f}\")\n",
        "    \n",
        "    return oof_predictions, test_predictions, calibrator, calibrated_mae, adv_auc\n",
        "\n",
        "print(\"‚úÖ MAE-optimized training with calibration loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete Training Pipeline with Calibration\n",
        "def train_all_targets_with_calibration(train_df, test_df, targets=['Tg', 'FFV', 'Tc', 'Density', 'Rg']):\n",
        "    \"\"\"\n",
        "    Train all targets with MAE optimization and isotonic calibration\n",
        "    \"\"\"\n",
        "    print(\"üöÄ COMPLETE TRAINING PIPELINE WITH CALIBRATION\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    results = {}\n",
        "    calibrators = {}\n",
        "    test_predictions = {}\n",
        "    \n",
        "    for target in targets:\n",
        "        print(f\"\\n{'='*20} {target} {'='*20}\")\n",
        "        \n",
        "        try:\n",
        "            oof_preds, test_preds, calibrator, mae, adv_auc = train_mae_calibrated_cv(\n",
        "                train_df, test_df, target, n_folds=3, n_clusters=15\n",
        "            )\n",
        "            \n",
        "            if oof_preds is not None:\n",
        "                results[target] = {\n",
        "                    'mae': mae,\n",
        "                    'adv_auc': adv_auc,\n",
        "                    'oof_predictions': oof_preds\n",
        "                }\n",
        "                calibrators[target] = calibrator\n",
        "                test_predictions[target] = test_preds\n",
        "                \n",
        "                print(f\"‚úÖ {target} completed - MAE: {mae:.4f}, Adversarial AUC: {adv_auc:.4f}\")\n",
        "            else:\n",
        "                print(f\"‚ùå {target} failed\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error training {target}: {e}\")\n",
        "    \n",
        "    # Apply calibration to test predictions\n",
        "    print(\"\\nüîß Applying calibration to test predictions...\")\n",
        "    calibrated_test_predictions = {}\n",
        "    \n",
        "    for target, predictions in test_predictions.items():\n",
        "        if target in calibrators:\n",
        "            calibrated_pred = calibrators[target].predict(predictions)\n",
        "            calibrated_test_predictions[target] = calibrated_pred\n",
        "            print(f\"‚úÖ {target}: Applied calibration\")\n",
        "        else:\n",
        "            calibrated_test_predictions[target] = predictions\n",
        "            print(f\"‚ö†Ô∏è {target}: No calibrator available\")\n",
        "    \n",
        "    # Create submission dataframe\n",
        "    submission_df = pd.DataFrame({'id': test_df['id']})\n",
        "    for target in targets:\n",
        "        if target in calibrated_test_predictions:\n",
        "            submission_df[target] = calibrated_test_predictions[target]\n",
        "        else:\n",
        "            submission_df[target] = 0.0\n",
        "    \n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä CALIBRATION RESULTS SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for target in targets:\n",
        "        if target in results:\n",
        "            mae = results[target]['mae']\n",
        "            adv_auc = results[target]['adv_auc']\n",
        "            print(f\"{target:8s}: MAE = {mae:.4f}, Adversarial AUC = {adv_auc:.4f}\")\n",
        "        else:\n",
        "            print(f\"{target:8s}: Failed\")\n",
        "    \n",
        "    avg_mae = np.mean([results[t]['mae'] for t in targets if t in results])\n",
        "    print(f\"\\nüìà Average MAE: {avg_mae:.4f}\")\n",
        "    \n",
        "    # Calibration info\n",
        "    print(\"\\nüîß Calibration Information:\")\n",
        "    for target, calibrator in calibrators.items():\n",
        "        print(f\"  {calibrator.get_calibration_info()}\")\n",
        "    \n",
        "    return results, calibrators, submission_df\n",
        "\n",
        "print(\"‚úÖ Complete training pipeline with calibration loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the Complete Pipeline\n",
        "print(\"üß™ TESTING COMPLETE PIPELINE WITH CALIBRATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create sample data for testing\n",
        "print(\"üìä Creating sample data...\")\n",
        "\n",
        "sample_train = pd.DataFrame({\n",
        "    'SMILES': [\n",
        "        'CCO', 'CC(C)O', 'CC(C)(C)O', 'C1=CC=CC=C1', 'C1=CC=CC=C1O',\n",
        "        'CCCC', 'CC(C)CC', 'C1=CC=CC=C1C', 'CC(C)(C)CC', 'C1=CC=CC=C1CC'\n",
        "    ],\n",
        "    'Tg': [100.0, 120.0, 140.0, 80.0, 90.0, 110.0, 130.0, 85.0, 150.0, 95.0],\n",
        "    'FFV': [0.1, 0.15, 0.2, 0.05, 0.08, 0.12, 0.18, 0.06, 0.22, 0.09],\n",
        "    'Tc': [200.0, 220.0, 240.0, 180.0, 190.0, 210.0, 230.0, 185.0, 250.0, 195.0],\n",
        "    'Density': [1.0, 1.1, 1.2, 0.9, 0.95, 1.05, 1.15, 0.92, 1.25, 0.98],\n",
        "    'Rg': [5.0, 6.0, 7.0, 4.0, 4.5, 5.5, 6.5, 4.2, 7.5, 4.8]\n",
        "})\n",
        "\n",
        "sample_test = pd.DataFrame({\n",
        "    'SMILES': ['CCCCC', 'CC(C)CCC', 'C1=CC=CC=C1CC'],\n",
        "    'id': [1, 2, 3]\n",
        "})\n",
        "\n",
        "print(f\"Train shape: {sample_train.shape}\")\n",
        "print(f\"Test shape: {sample_test.shape}\")\n",
        "\n",
        "# Test the complete pipeline\n",
        "try:\n",
        "    results, calibrators, submission_df = train_all_targets_with_calibration(\n",
        "        sample_train, sample_test, targets=['Tg', 'FFV']  # Test with 2 targets first\n",
        "    )\n",
        "    \n",
        "    print(\"\\nüéâ Pipeline test completed successfully!\")\n",
        "    print(f\"\\nüìã Submission shape: {submission_df.shape}\")\n",
        "    print(\"\\nüìä Submission preview:\")\n",
        "    print(submission_df.head())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Pipeline test failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã Next steps:\")\n",
        "print(\"1. Load your actual train/test data\")\n",
        "print(\"2. Run train_all_targets_with_calibration() with all 5 targets\")\n",
        "print(\"3. Compare MAE scores before/after calibration\")\n",
        "print(\"4. Expected improvement: +0.010-0.025 wMAE reduction\")\n",
        "print(\"5. Save submission_df.to_csv('calibrated_submission.csv', index=False)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
